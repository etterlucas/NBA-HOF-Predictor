{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Testing Evaluation and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from joblib import dump,load\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "knn = load('./Models/knn')\n",
    "svc = load('./Models/svc')\n",
    "ada = load('./Models/ada')\n",
    "gbc = load('./Models/gbc')\n",
    "xgb = load('./Models/xgb')\n",
    "vc_soft = load('./Models/vc_soft')\n",
    "vc_hard = load('./Models/vc_hard')\n",
    "sc = load('./Models/sc')\n",
    "nn = tf.keras.models.load_model('./Models/nn/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "X_test = pd.read_csv('./Data/X_test.csv',index_col=0)\n",
    "y_test = pd.read_csv('./Data/y_test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other information\n",
    "df_final = pd.read_csv('./Data/final_cleaned.csv',index_col=0)\n",
    "test_indices = pd.read_csv('./Data/test_indices.csv',index_col=0).values.tolist()\n",
    "test_indices = [val for sublist in test_indices for val in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Model Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now evaluate each of the models based on their performance on the test data. F1-score will remain as the primary metric for evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Tuned k-nearest neighbors with tuned bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1-score\n",
    "f1_score(y_test,predictions_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[526   6]\n",
      " [  6  15]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       532\n",
      "           1       0.71      0.71      0.71        21\n",
      "\n",
      "    accuracy                           0.98       553\n",
      "   macro avg       0.85      0.85      0.85       553\n",
      "weighted avg       0.98      0.98      0.98       553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Tuned support vector machine with tuned bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_svc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7555555555555556"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1-score\n",
    "f1_score(y_test,predictions_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[525   7]\n",
      " [  4  17]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       532\n",
      "           1       0.71      0.81      0.76        21\n",
      "\n",
      "    accuracy                           0.98       553\n",
      "   macro avg       0.85      0.90      0.87       553\n",
      "weighted avg       0.98      0.98      0.98       553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Tuned AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ada = ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.717948717948718"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1-score\n",
    "f1_score(y_test,predictions_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[528   4]\n",
      " [  7  14]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       532\n",
      "           1       0.78      0.67      0.72        21\n",
      "\n",
      "    accuracy                           0.98       553\n",
      "   macro avg       0.88      0.83      0.85       553\n",
      "weighted avg       0.98      0.98      0.98       553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Tuned gradient tree boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_gbc = gbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.717948717948718"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1-score\n",
    "f1_score(y_test,predictions_gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[528   4]\n",
      " [  7  14]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       532\n",
      "           1       0.78      0.67      0.72        21\n",
      "\n",
      "    accuracy                           0.98       553\n",
      "   macro avg       0.88      0.83      0.85       553\n",
      "weighted avg       0.98      0.98      0.98       553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions_gbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Tuned XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_xgb = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6956521739130435"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1-score\n",
    "f1_score(y_test,predictions_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[523   9]\n",
      " [  5  16]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       532\n",
      "           1       0.64      0.76      0.70        21\n",
      "\n",
      "    accuracy                           0.97       553\n",
      "   macro avg       0.82      0.87      0.84       553\n",
      "weighted avg       0.98      0.97      0.98       553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Voting classifier (soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_vc_soft = vc_soft.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8095238095238095"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1-score\n",
    "f1_score(y_test,predictions_vc_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[528   4]\n",
      " [  4  17]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions_vc_soft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       532\n",
      "           1       0.81      0.81      0.81        21\n",
      "\n",
      "    accuracy                           0.99       553\n",
      "   macro avg       0.90      0.90      0.90       553\n",
      "weighted avg       0.99      0.99      0.99       553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions_vc_soft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Voting classifier (hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_vc_hard = vc_hard.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7567567567567567"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1-score\n",
    "f1_score(y_test,predictions_vc_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[530   2]\n",
      " [  7  14]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions_vc_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       532\n",
      "           1       0.88      0.67      0.76        21\n",
      "\n",
      "    accuracy                           0.98       553\n",
      "   macro avg       0.93      0.83      0.87       553\n",
      "weighted avg       0.98      0.98      0.98       553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions_vc_hard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Stacking classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_sc = sc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.717948717948718"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1-score\n",
    "f1_score(y_test,predictions_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[528   4]\n",
      " [  7  14]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       532\n",
      "           1       0.78      0.67      0.72        21\n",
      "\n",
      "    accuracy                           0.98       553\n",
      "   macro avg       0.88      0.83      0.85       553\n",
      "weighted avg       0.98      0.98      0.98       553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions_sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Tuned neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-37-9ee414e00444>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "predictions_nn = nn.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making neural-network predictions one-dimensional\n",
    "predictions_nn = [val for sublist in predictions_nn for val in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1-score\n",
    "f1_score(y_test,predictions_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[519  13]\n",
      " [  4  17]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       532\n",
      "           1       0.57      0.81      0.67        21\n",
      "\n",
      "    accuracy                           0.97       553\n",
      "   macro avg       0.78      0.89      0.83       553\n",
      "weighted avg       0.98      0.97      0.97       553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, we can conclude that the soft voting classifier performs the best. It boasts the highest f1-score on the test data, which can be attributed to its high accuracy and balanced misclassifications. This result is not especially surprising since, after all, voting classifiers are constituted by a wide variety of models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Visualizing Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first look at how much consensus there was in our models' predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({'K-Nearest Neighbors':predictions_knn,'Support Vector Machine':predictions_svc,'AdaBoost':predictions_ada,'Gradient Tree Boosting':predictions_gbc,'XGBoost':predictions_xgb,'Soft Voting Classifier':predictions_vc_soft,'Hard Voting Classifier':predictions_vc_hard,'Stacking Classifier':predictions_sc,'Neural Network':predictions_nn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Gradient Tree Boosting</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>Soft Voting Classifier</th>\n",
       "      <th>Hard Voting Classifier</th>\n",
       "      <th>Stacking Classifier</th>\n",
       "      <th>Neural Network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>553 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     K-Nearest Neighbors  Support Vector Machine  AdaBoost  \\\n",
       "0                      0                       0         0   \n",
       "1                      0                       0         0   \n",
       "2                      0                       0         1   \n",
       "3                      0                       0         0   \n",
       "4                      0                       0         0   \n",
       "..                   ...                     ...       ...   \n",
       "548                    0                       0         0   \n",
       "549                    0                       0         0   \n",
       "550                    0                       0         0   \n",
       "551                    0                       0         0   \n",
       "552                    0                       0         0   \n",
       "\n",
       "     Gradient Tree Boosting  XGBoost  Soft Voting Classifier  \\\n",
       "0                         0        0                       0   \n",
       "1                         0        0                       0   \n",
       "2                         1        1                       1   \n",
       "3                         0        0                       0   \n",
       "4                         0        0                       0   \n",
       "..                      ...      ...                     ...   \n",
       "548                       0        0                       0   \n",
       "549                       0        0                       0   \n",
       "550                       0        0                       0   \n",
       "551                       0        0                       0   \n",
       "552                       0        0                       0   \n",
       "\n",
       "     Hard Voting Classifier  Stacking Classifier  Neural Network  \n",
       "0                         0                    0               0  \n",
       "1                         0                    0               0  \n",
       "2                         0                    1               1  \n",
       "3                         0                    0               0  \n",
       "4                         0                    0               0  \n",
       "..                      ...                  ...             ...  \n",
       "548                       0                    0               0  \n",
       "549                       0                    0               0  \n",
       "550                       0                    0               0  \n",
       "551                       0                    0               0  \n",
       "552                       0                    0               0  \n",
       "\n",
       "[553 rows x 9 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    516\n",
       "1      7\n",
       "2      7\n",
       "3      1\n",
       "4      2\n",
       "5      1\n",
       "6      3\n",
       "7      2\n",
       "8      4\n",
       "9     10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.sum(axis=1).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that only seven of the 553 players were highly disputed - having a sum between 3 and 6. The majority of the misclassifications by each model were likely comprised of these seven players."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now look at plots of the accuracy score and the f1-score for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for model in predictions.columns:\n",
    "    accuracy = accuracy_score(y_test,predictions[model])\n",
    "    f1 = f1_score(y_test,predictions[model])\n",
    "    scores.append((accuracy,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9783001808318263, 0.7142857142857143),\n",
       " (0.9801084990958409, 0.7555555555555556),\n",
       " (0.9801084990958409, 0.717948717948718),\n",
       " (0.9801084990958409, 0.717948717948718),\n",
       " (0.9746835443037974, 0.6956521739130435),\n",
       " (0.9855334538878843, 0.8095238095238095),\n",
       " (0.9837251356238698, 0.7567567567567567),\n",
       " (0.9801084990958409, 0.717948717948718),\n",
       " (0.969258589511754, 0.6666666666666666)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame({'Model':predictions.columns,'Scores':scores})\n",
    "scores_df['Accuracy'] = scores_df['Scores'].apply(lambda x:x[0])\n",
    "scores_df['F1-Score'] = scores_df['Scores'].apply(lambda x:x[1])\n",
    "scores_df = scores_df.drop(['Scores'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.978300</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.980108</td>\n",
       "      <td>0.755556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.980108</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Tree Boosting</td>\n",
       "      <td>0.980108</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Soft Voting Classifier</td>\n",
       "      <td>0.985533</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hard Voting Classifier</td>\n",
       "      <td>0.983725</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stacking Classifier</td>\n",
       "      <td>0.980108</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.969259</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy  F1-Score\n",
       "0     K-Nearest Neighbors  0.978300  0.714286\n",
       "1  Support Vector Machine  0.980108  0.755556\n",
       "2                AdaBoost  0.980108  0.717949\n",
       "3  Gradient Tree Boosting  0.980108  0.717949\n",
       "4                 XGBoost  0.974684  0.695652\n",
       "5  Soft Voting Classifier  0.985533  0.809524\n",
       "6  Hard Voting Classifier  0.983725  0.756757\n",
       "7     Stacking Classifier  0.980108  0.717949\n",
       "8          Neural Network  0.969259  0.666667"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df_modified = pd.melt(scores_df,id_vars='Model',var_name='Score Type',value_name='Proportion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score Type</th>\n",
       "      <th>Proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.978300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.980108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.980108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Tree Boosting</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.980108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.974684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Soft Voting Classifier</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.985533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hard Voting Classifier</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.983725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stacking Classifier</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.980108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.969259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.755556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gradient Tree Boosting</td>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Soft Voting Classifier</td>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hard Voting Classifier</td>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking Classifier</td>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model Score Type  Proportion\n",
       "0      K-Nearest Neighbors   Accuracy    0.978300\n",
       "1   Support Vector Machine   Accuracy    0.980108\n",
       "2                 AdaBoost   Accuracy    0.980108\n",
       "3   Gradient Tree Boosting   Accuracy    0.980108\n",
       "4                  XGBoost   Accuracy    0.974684\n",
       "5   Soft Voting Classifier   Accuracy    0.985533\n",
       "6   Hard Voting Classifier   Accuracy    0.983725\n",
       "7      Stacking Classifier   Accuracy    0.980108\n",
       "8           Neural Network   Accuracy    0.969259\n",
       "9      K-Nearest Neighbors   F1-Score    0.714286\n",
       "10  Support Vector Machine   F1-Score    0.755556\n",
       "11                AdaBoost   F1-Score    0.717949\n",
       "12  Gradient Tree Boosting   F1-Score    0.717949\n",
       "13                 XGBoost   F1-Score    0.695652\n",
       "14  Soft Voting Classifier   F1-Score    0.809524\n",
       "15  Hard Voting Classifier   F1-Score    0.756757\n",
       "16     Stacking Classifier   F1-Score    0.717949\n",
       "17          Neural Network   F1-Score    0.666667"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 756x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('darkgrid')\n",
    "sns.catplot(x='Proportion',y='Model',hue='Score Type',data=scores_df_modified,kind='bar',height=7,aspect=1.5,legend=False)\n",
    "\n",
    "plt.ylabel('Model',fontsize=16)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlabel('Score',fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.title('Model Performance',fontsize=20)\n",
    "plt.legend(fontsize=12,title='Score Type',title_fontsize=16,bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "plt.xlim([.6,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be quite obvious that the soft voting classifier outperforms the rest of the models. Both the accuracy and f1-score metrics support this conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. Saving Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save the soft voting classifier as our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = vc_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Models/final_model']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(final_model,'./Models/final_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5. Reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a more concrete idea of how our model performed, we will pair our predictions with the original, unprocessed test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_test = df_final.iloc[test_indices]\n",
    "df_final_test = df_final_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>G_sum</th>\n",
       "      <th>GS_sum</th>\n",
       "      <th>MP_sum</th>\n",
       "      <th>FG_sum</th>\n",
       "      <th>2P_sum</th>\n",
       "      <th>FT_sum</th>\n",
       "      <th>TRB_sum</th>\n",
       "      <th>AST_sum</th>\n",
       "      <th>PF_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>award_count</th>\n",
       "      <th>all_team_awards</th>\n",
       "      <th>league_awards</th>\n",
       "      <th>years_coaching</th>\n",
       "      <th>lottery</th>\n",
       "      <th>hof</th>\n",
       "      <th>all_star_count</th>\n",
       "      <th>championships</th>\n",
       "      <th>O</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Norm Swanson</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frank Williams</td>\n",
       "      <td>86.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ray Scott</td>\n",
       "      <td>756.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23785.0</td>\n",
       "      <td>4364.0</td>\n",
       "      <td>4364.0</td>\n",
       "      <td>2628.0</td>\n",
       "      <td>7914.0</td>\n",
       "      <td>1778.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skip Harlicka</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Byron Irvin</td>\n",
       "      <td>87.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>Victor Alexander</td>\n",
       "      <td>286.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>5755.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Terry Davis</td>\n",
       "      <td>480.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>10369.0</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>2887.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>Quintin Dailey</td>\n",
       "      <td>528.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12170.0</td>\n",
       "      <td>2936.0</td>\n",
       "      <td>2915.0</td>\n",
       "      <td>1577.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>Sean Marks</td>\n",
       "      <td>230.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2275.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>John Rudometkin</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>553 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Player  G_sum  GS_sum   MP_sum  FG_sum  2P_sum  FT_sum  \\\n",
       "0        Norm Swanson   63.0     0.0    611.0    31.0    31.0    38.0   \n",
       "1      Frank Williams   86.0     3.0    952.0    92.0    68.0    45.0   \n",
       "2           Ray Scott  756.0     0.0  23785.0  4364.0  4364.0  2628.0   \n",
       "3       Skip Harlicka   26.0     0.0    218.0    41.0    41.0    24.0   \n",
       "4         Byron Irvin   87.0     8.0    849.0   165.0   158.0   114.0   \n",
       "..                ...    ...     ...      ...     ...     ...     ...   \n",
       "548  Victor Alexander  286.0   155.0   5755.0  1101.0  1083.0   322.0   \n",
       "549       Terry Davis  480.0   275.0  10369.0  1202.0  1199.0   654.0   \n",
       "550    Quintin Dailey  528.0   140.0  12170.0  2936.0  2915.0  1577.0   \n",
       "551        Sean Marks  230.0    11.0   2275.0   259.0   254.0   115.0   \n",
       "552   John Rudometkin  154.0     0.0   2020.0   366.0   366.0   228.0   \n",
       "\n",
       "     TRB_sum  AST_sum  PF_sum  ...  award_count  all_team_awards  \\\n",
       "0      110.0     33.0    91.0  ...            0                0   \n",
       "1       77.0    166.0    87.0  ...            0                0   \n",
       "2     7914.0   1778.0  2250.0  ...            1                0   \n",
       "3       16.0     37.0    29.0  ...            0                0   \n",
       "4      123.0     73.0    77.0  ...            0                0   \n",
       "..       ...      ...     ...  ...          ...              ...   \n",
       "548   1384.0    257.0   713.0  ...            0                0   \n",
       "549   2887.0    273.0  1176.0  ...            0                0   \n",
       "550   1307.0   1188.0  1231.0  ...            0                0   \n",
       "551    501.0     50.0   342.0  ...            0                0   \n",
       "552    511.0     88.0   252.0  ...            0                0   \n",
       "\n",
       "     league_awards  years_coaching  lottery  hof  all_star_count  \\\n",
       "0                0               0        0    0               0   \n",
       "1                0               0        0    0               0   \n",
       "2                0               4        1    0               0   \n",
       "3                0               0        1    0               0   \n",
       "4                0               0        0    0               0   \n",
       "..             ...             ...      ...  ...             ...   \n",
       "548              0               0        0    0               0   \n",
       "549              0               0        0    0               0   \n",
       "550              0               0        1    0               0   \n",
       "551              0               0        0    0               0   \n",
       "552              0               0        1    0               0   \n",
       "\n",
       "     championships  O  W  \n",
       "0                0  0  1  \n",
       "1                0  0  0  \n",
       "2                0  0  0  \n",
       "3                0  0  1  \n",
       "4                0  0  0  \n",
       "..             ... .. ..  \n",
       "548              0  0  0  \n",
       "549              0  0  0  \n",
       "550              0  0  0  \n",
       "551              1  0  1  \n",
       "552              0  0  1  \n",
       "\n",
       "[553 rows x 34 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_test = pd.concat([df_final_test,pd.DataFrame({'hof_predicted':predictions_vc_soft})],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>G_sum</th>\n",
       "      <th>GS_sum</th>\n",
       "      <th>MP_sum</th>\n",
       "      <th>FG_sum</th>\n",
       "      <th>2P_sum</th>\n",
       "      <th>FT_sum</th>\n",
       "      <th>TRB_sum</th>\n",
       "      <th>AST_sum</th>\n",
       "      <th>PF_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>all_team_awards</th>\n",
       "      <th>league_awards</th>\n",
       "      <th>years_coaching</th>\n",
       "      <th>lottery</th>\n",
       "      <th>hof</th>\n",
       "      <th>all_star_count</th>\n",
       "      <th>championships</th>\n",
       "      <th>O</th>\n",
       "      <th>W</th>\n",
       "      <th>hof_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Norm Swanson</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frank Williams</td>\n",
       "      <td>86.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ray Scott</td>\n",
       "      <td>756.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23785.0</td>\n",
       "      <td>4364.0</td>\n",
       "      <td>4364.0</td>\n",
       "      <td>2628.0</td>\n",
       "      <td>7914.0</td>\n",
       "      <td>1778.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skip Harlicka</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Byron Irvin</td>\n",
       "      <td>87.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>Victor Alexander</td>\n",
       "      <td>286.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>5755.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Terry Davis</td>\n",
       "      <td>480.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>10369.0</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>2887.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>Quintin Dailey</td>\n",
       "      <td>528.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12170.0</td>\n",
       "      <td>2936.0</td>\n",
       "      <td>2915.0</td>\n",
       "      <td>1577.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>Sean Marks</td>\n",
       "      <td>230.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2275.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>John Rudometkin</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>553 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Player  G_sum  GS_sum   MP_sum  FG_sum  2P_sum  FT_sum  \\\n",
       "0        Norm Swanson   63.0     0.0    611.0    31.0    31.0    38.0   \n",
       "1      Frank Williams   86.0     3.0    952.0    92.0    68.0    45.0   \n",
       "2           Ray Scott  756.0     0.0  23785.0  4364.0  4364.0  2628.0   \n",
       "3       Skip Harlicka   26.0     0.0    218.0    41.0    41.0    24.0   \n",
       "4         Byron Irvin   87.0     8.0    849.0   165.0   158.0   114.0   \n",
       "..                ...    ...     ...      ...     ...     ...     ...   \n",
       "548  Victor Alexander  286.0   155.0   5755.0  1101.0  1083.0   322.0   \n",
       "549       Terry Davis  480.0   275.0  10369.0  1202.0  1199.0   654.0   \n",
       "550    Quintin Dailey  528.0   140.0  12170.0  2936.0  2915.0  1577.0   \n",
       "551        Sean Marks  230.0    11.0   2275.0   259.0   254.0   115.0   \n",
       "552   John Rudometkin  154.0     0.0   2020.0   366.0   366.0   228.0   \n",
       "\n",
       "     TRB_sum  AST_sum  PF_sum  ...  all_team_awards  league_awards  \\\n",
       "0      110.0     33.0    91.0  ...                0              0   \n",
       "1       77.0    166.0    87.0  ...                0              0   \n",
       "2     7914.0   1778.0  2250.0  ...                0              0   \n",
       "3       16.0     37.0    29.0  ...                0              0   \n",
       "4      123.0     73.0    77.0  ...                0              0   \n",
       "..       ...      ...     ...  ...              ...            ...   \n",
       "548   1384.0    257.0   713.0  ...                0              0   \n",
       "549   2887.0    273.0  1176.0  ...                0              0   \n",
       "550   1307.0   1188.0  1231.0  ...                0              0   \n",
       "551    501.0     50.0   342.0  ...                0              0   \n",
       "552    511.0     88.0   252.0  ...                0              0   \n",
       "\n",
       "     years_coaching  lottery  hof  all_star_count  championships  O  W  \\\n",
       "0                 0        0    0               0              0  0  1   \n",
       "1                 0        0    0               0              0  0  0   \n",
       "2                 4        1    0               0              0  0  0   \n",
       "3                 0        1    0               0              0  0  1   \n",
       "4                 0        0    0               0              0  0  0   \n",
       "..              ...      ...  ...             ...            ... .. ..   \n",
       "548               0        0    0               0              0  0  0   \n",
       "549               0        0    0               0              0  0  0   \n",
       "550               0        1    0               0              0  0  0   \n",
       "551               0        0    0               0              1  0  1   \n",
       "552               0        1    0               0              0  0  1   \n",
       "\n",
       "     hof_predicted  \n",
       "0                0  \n",
       "1                0  \n",
       "2                1  \n",
       "3                0  \n",
       "4                0  \n",
       "..             ...  \n",
       "548              0  \n",
       "549              0  \n",
       "550              0  \n",
       "551              0  \n",
       "552              0  \n",
       "\n",
       "[553 rows x 35 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data with predictions appended\n",
    "df_final_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the hall-of-fame players that we correctly predicted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>G_sum</th>\n",
       "      <th>GS_sum</th>\n",
       "      <th>MP_sum</th>\n",
       "      <th>FG_sum</th>\n",
       "      <th>2P_sum</th>\n",
       "      <th>FT_sum</th>\n",
       "      <th>TRB_sum</th>\n",
       "      <th>AST_sum</th>\n",
       "      <th>PF_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>all_team_awards</th>\n",
       "      <th>league_awards</th>\n",
       "      <th>years_coaching</th>\n",
       "      <th>lottery</th>\n",
       "      <th>hof</th>\n",
       "      <th>all_star_count</th>\n",
       "      <th>championships</th>\n",
       "      <th>O</th>\n",
       "      <th>W</th>\n",
       "      <th>hof_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Red Holzman</td>\n",
       "      <td>298.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2106.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>George Yardley</td>\n",
       "      <td>533.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17606.0</td>\n",
       "      <td>3639.0</td>\n",
       "      <td>3639.0</td>\n",
       "      <td>2994.0</td>\n",
       "      <td>4651.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Al Cervi</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Karl Malone</td>\n",
       "      <td>1476.0</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>54852.0</td>\n",
       "      <td>13528.0</td>\n",
       "      <td>13443.0</td>\n",
       "      <td>9787.0</td>\n",
       "      <td>14968.0</td>\n",
       "      <td>5248.0</td>\n",
       "      <td>4578.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Paul Arizin</td>\n",
       "      <td>713.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24897.0</td>\n",
       "      <td>5628.0</td>\n",
       "      <td>5628.0</td>\n",
       "      <td>5010.0</td>\n",
       "      <td>6129.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>2764.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Magic Johnson</td>\n",
       "      <td>906.0</td>\n",
       "      <td>763.0</td>\n",
       "      <td>33245.0</td>\n",
       "      <td>6211.0</td>\n",
       "      <td>5886.0</td>\n",
       "      <td>4960.0</td>\n",
       "      <td>6559.0</td>\n",
       "      <td>10141.0</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Connie Hawkins</td>\n",
       "      <td>578.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19995.0</td>\n",
       "      <td>3417.0</td>\n",
       "      <td>3417.0</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>4536.0</td>\n",
       "      <td>2459.0</td>\n",
       "      <td>1682.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Hakeem Olajuwon</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>1186.0</td>\n",
       "      <td>44222.0</td>\n",
       "      <td>10749.0</td>\n",
       "      <td>10724.0</td>\n",
       "      <td>5423.0</td>\n",
       "      <td>13748.0</td>\n",
       "      <td>3058.0</td>\n",
       "      <td>4383.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Jerry Lucas</td>\n",
       "      <td>896.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34551.0</td>\n",
       "      <td>6114.0</td>\n",
       "      <td>6114.0</td>\n",
       "      <td>2835.0</td>\n",
       "      <td>13893.0</td>\n",
       "      <td>2907.0</td>\n",
       "      <td>2551.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>Bailey Howell</td>\n",
       "      <td>950.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30627.0</td>\n",
       "      <td>6515.0</td>\n",
       "      <td>6515.0</td>\n",
       "      <td>4740.0</td>\n",
       "      <td>9383.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>3498.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>Jerry Sloan</td>\n",
       "      <td>755.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25750.0</td>\n",
       "      <td>4116.0</td>\n",
       "      <td>4116.0</td>\n",
       "      <td>2339.0</td>\n",
       "      <td>5615.0</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Larry Bird</td>\n",
       "      <td>897.0</td>\n",
       "      <td>870.0</td>\n",
       "      <td>34443.0</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>7942.0</td>\n",
       "      <td>3960.0</td>\n",
       "      <td>8974.0</td>\n",
       "      <td>5695.0</td>\n",
       "      <td>2279.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>Bobby Wanzer</td>\n",
       "      <td>508.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12128.0</td>\n",
       "      <td>2066.0</td>\n",
       "      <td>2066.0</td>\n",
       "      <td>2179.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>1644.0</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>Wilt Chamberlain</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51160.0</td>\n",
       "      <td>13744.0</td>\n",
       "      <td>13744.0</td>\n",
       "      <td>6465.0</td>\n",
       "      <td>25597.0</td>\n",
       "      <td>4893.0</td>\n",
       "      <td>2221.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>Dan Issel</td>\n",
       "      <td>718.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>22342.0</td>\n",
       "      <td>5424.0</td>\n",
       "      <td>5405.0</td>\n",
       "      <td>3792.0</td>\n",
       "      <td>5707.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>Reggie Miller</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>47619.0</td>\n",
       "      <td>8241.0</td>\n",
       "      <td>5681.0</td>\n",
       "      <td>6237.0</td>\n",
       "      <td>4182.0</td>\n",
       "      <td>4141.0</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>Alex Hannum</td>\n",
       "      <td>516.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7713.0</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Player   G_sum  GS_sum   MP_sum   FG_sum   2P_sum  FT_sum  \\\n",
       "9         Red Holzman   298.0     0.0   2106.0    605.0    605.0   410.0   \n",
       "19     George Yardley   533.0     0.0  17606.0   3639.0   3639.0  2994.0   \n",
       "40           Al Cervi   202.0     0.0   1151.0    405.0    405.0   781.0   \n",
       "176       Karl Malone  1476.0  1471.0  54852.0  13528.0  13443.0  9787.0   \n",
       "257       Paul Arizin   713.0     0.0  24897.0   5628.0   5628.0  5010.0   \n",
       "264     Magic Johnson   906.0   763.0  33245.0   6211.0   5886.0  4960.0   \n",
       "306    Connie Hawkins   578.0     0.0  19995.0   3417.0   3417.0  2398.0   \n",
       "328   Hakeem Olajuwon  1238.0  1186.0  44222.0  10749.0  10724.0  5423.0   \n",
       "352       Jerry Lucas   896.0     0.0  34551.0   6114.0   6114.0  2835.0   \n",
       "430     Bailey Howell   950.0     0.0  30627.0   6515.0   6515.0  4740.0   \n",
       "451       Jerry Sloan   755.0     0.0  25750.0   4116.0   4116.0  2339.0   \n",
       "461        Larry Bird   897.0   870.0  34443.0   8591.0   7942.0  3960.0   \n",
       "471      Bobby Wanzer   508.0     0.0  12128.0   2066.0   2066.0  2179.0   \n",
       "472  Wilt Chamberlain  1118.0     0.0  51160.0  13744.0  13744.0  6465.0   \n",
       "492         Dan Issel   718.0   236.0  22342.0   5424.0   5405.0  3792.0   \n",
       "512     Reggie Miller  1389.0  1304.0  47619.0   8241.0   5681.0  6237.0   \n",
       "546       Alex Hannum   516.0     0.0   7713.0   1182.0   1182.0   714.0   \n",
       "\n",
       "     TRB_sum  AST_sum  PF_sum  ...  all_team_awards  league_awards  \\\n",
       "9      344.0    572.0   385.0  ...                0              1   \n",
       "19    4651.0    880.0  1585.0  ...                2              0   \n",
       "40     261.0    648.0   669.0  ...                1              0   \n",
       "176  14968.0   5248.0  4578.0  ...               18              2   \n",
       "257   6129.0   1665.0  2764.0  ...                4              0   \n",
       "264   6559.0  10141.0  2050.0  ...               10              6   \n",
       "306   4536.0   2459.0  1682.0  ...                3              3   \n",
       "328  13748.0   3058.0  4383.0  ...               21              5   \n",
       "352  13893.0   2907.0  2551.0  ...                5              1   \n",
       "430   9383.0   1853.0  3498.0  ...                1              0   \n",
       "451   5615.0   1925.0  2700.0  ...                6              0   \n",
       "461   8974.0   5695.0  2279.0  ...               13              6   \n",
       "471   1979.0   1644.0  1143.0  ...                3              0   \n",
       "472  25597.0   4893.0  2221.0  ...               12              6   \n",
       "492   5707.0   1804.0  2022.0  ...                5              1   \n",
       "512   4182.0   4141.0  2730.0  ...                3              0   \n",
       "546   2013.0    857.0  1955.0  ...                0              0   \n",
       "\n",
       "     years_coaching  lottery  hof  all_star_count  championships  O  W  \\\n",
       "9                18        0    1               0              2  0  1   \n",
       "19                0        1    1               6              0  0  1   \n",
       "40                9        0    1               0              1  0  1   \n",
       "176               0        1    1              13              0  0  0   \n",
       "257               0        0    1              10              1  0  1   \n",
       "264               1        1    1               3              0  0  0   \n",
       "306               0        0    1               5              0  0  0   \n",
       "328               0        1    1              12              2  0  0   \n",
       "352               0        0    1               7              1  0  1   \n",
       "430               0        1    1               6              2  0  1   \n",
       "451              26        0    1               2              0  0  1   \n",
       "461               3        1    1              12              3  0  1   \n",
       "471               4        1    1               5              0  0  1   \n",
       "472               1        0    1              13              0  0  0   \n",
       "492               6        0    1               7              0  0  1   \n",
       "512               0        1    1               5              0  0  0   \n",
       "546              16        0    1               0              3  0  1   \n",
       "\n",
       "     hof_predicted  \n",
       "9                1  \n",
       "19               1  \n",
       "40               1  \n",
       "176              1  \n",
       "257              1  \n",
       "264              1  \n",
       "306              1  \n",
       "328              1  \n",
       "352              1  \n",
       "430              1  \n",
       "451              1  \n",
       "461              1  \n",
       "471              1  \n",
       "472              1  \n",
       "492              1  \n",
       "512              1  \n",
       "546              1  \n",
       "\n",
       "[17 rows x 35 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_test[(df_final_test['hof']==1) & (df_final_test['hof_predicted']==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are all of the players that we incorrectly predicted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>G_sum</th>\n",
       "      <th>GS_sum</th>\n",
       "      <th>MP_sum</th>\n",
       "      <th>FG_sum</th>\n",
       "      <th>2P_sum</th>\n",
       "      <th>FT_sum</th>\n",
       "      <th>TRB_sum</th>\n",
       "      <th>AST_sum</th>\n",
       "      <th>PF_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>all_team_awards</th>\n",
       "      <th>league_awards</th>\n",
       "      <th>years_coaching</th>\n",
       "      <th>lottery</th>\n",
       "      <th>hof</th>\n",
       "      <th>all_star_count</th>\n",
       "      <th>championships</th>\n",
       "      <th>O</th>\n",
       "      <th>W</th>\n",
       "      <th>hof_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ray Scott</td>\n",
       "      <td>756.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23785.0</td>\n",
       "      <td>4364.0</td>\n",
       "      <td>4364.0</td>\n",
       "      <td>2628.0</td>\n",
       "      <td>7914.0</td>\n",
       "      <td>1778.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Slater Martin</td>\n",
       "      <td>811.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24290.0</td>\n",
       "      <td>2876.0</td>\n",
       "      <td>2876.0</td>\n",
       "      <td>2303.0</td>\n",
       "      <td>2590.0</td>\n",
       "      <td>3429.0</td>\n",
       "      <td>2431.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Dick McGuire</td>\n",
       "      <td>738.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17170.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1825.0</td>\n",
       "      <td>2784.0</td>\n",
       "      <td>4205.0</td>\n",
       "      <td>1695.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Rudy LaRusso</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24487.0</td>\n",
       "      <td>4102.0</td>\n",
       "      <td>4102.0</td>\n",
       "      <td>3303.0</td>\n",
       "      <td>6936.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>2553.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Calvin Murphy</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30607.0</td>\n",
       "      <td>7247.0</td>\n",
       "      <td>7237.0</td>\n",
       "      <td>3445.0</td>\n",
       "      <td>2103.0</td>\n",
       "      <td>4402.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>Charlie Scott</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21751.0</td>\n",
       "      <td>4548.0</td>\n",
       "      <td>4546.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>3074.0</td>\n",
       "      <td>2311.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>Larry Foust</td>\n",
       "      <td>817.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21890.0</td>\n",
       "      <td>3814.0</td>\n",
       "      <td>3814.0</td>\n",
       "      <td>3570.0</td>\n",
       "      <td>8041.0</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>2909.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>Fred Taylor</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Player   G_sum  GS_sum   MP_sum  FG_sum  2P_sum  FT_sum  TRB_sum  \\\n",
       "2        Ray Scott   756.0     0.0  23785.0  4364.0  4364.0  2628.0   7914.0   \n",
       "18   Slater Martin   811.0     0.0  24290.0  2876.0  2876.0  2303.0   2590.0   \n",
       "121   Dick McGuire   738.0     0.0  17170.0  2048.0  2048.0  1825.0   2784.0   \n",
       "209   Rudy LaRusso   736.0     0.0  24487.0  4102.0  4102.0  3303.0   6936.0   \n",
       "263  Calvin Murphy  1002.0     0.0  30607.0  7247.0  7237.0  3445.0   2103.0   \n",
       "360  Charlie Scott   639.0     0.0  21751.0  4548.0  4546.0  2003.0   2283.0   \n",
       "393    Larry Foust   817.0     0.0  21890.0  3814.0  3814.0  3570.0   8041.0   \n",
       "443    Fred Taylor   122.0     0.0   1118.0   182.0   182.0   108.0    194.0   \n",
       "\n",
       "     AST_sum  PF_sum  ...  all_team_awards  league_awards  years_coaching  \\\n",
       "2     1778.0  2250.0  ...                0              0               4   \n",
       "18    3429.0  2431.0  ...                5              0               3   \n",
       "121   4205.0  1695.0  ...                1              0               7   \n",
       "209   1556.0  2553.0  ...                1              0               0   \n",
       "263   4402.0  3250.0  ...                0              0               0   \n",
       "360   3074.0  2311.0  ...                2              1               0   \n",
       "393   1368.0  2909.0  ...                2              0               0   \n",
       "443     87.0   193.0  ...                0              0               0   \n",
       "\n",
       "     lottery  hof  all_star_count  championships  O  W  hof_predicted  \n",
       "2          1    0               0              0  0  0              1  \n",
       "18         0    1               7              4  0  1              0  \n",
       "121        1    1               7              0  0  1              0  \n",
       "209        1    0               5              0  0  1              1  \n",
       "263        0    1               1              0  0  0              0  \n",
       "360        0    0               5              0  0  0              1  \n",
       "393        1    0               8              0  0  1              1  \n",
       "443        0    1               0              0  0  0              0  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_test[df_final_test['hof']!=df_final_test['hof_predicted']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, we correctly classified all of the \"big names,\" such as Larry Bird or Wilt Chamberlain. Out of the players we misclassified, the two major suprises are Calvin Murphy and Fred Taylor due to their lack of accolades. \n",
    "\n",
    "It does appear that coaching experience plays a large part in the model. Although we did intend to use coaching as a factor, we probably should have limited the factors to playing. Nevertheless, we really had no easy way of determining whether a former player was inducted for his playing, coaching, or other contributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, based on our model's performance on the test data, we now have answers to these two fundamental questions:\n",
    "1. Given a random hall-of-fame NBA player, what are the odds that the model correctly predicts that player was inducted into the hall of fame?\n",
    "2. Given a random former NBA player, what are the odds that the model correctly predicts whether or not that player was inducted into the hall of fame?\n",
    "\n",
    "Here are the answer to the questions:\n",
    "1. Our model produced a recall score of 81% on the test data. Therefore, our model can correctly predict that a random hall-of-fame NBA player was inducted into the hall of fame 81% of the time. \n",
    "2. Our model produced an accuracy score of 99% on the test data. Therefore, our model can correctly predict whether or not a random former NBA player was inducted into the hall of fame 99% of the time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am happy to say that the model is also quite balanced in its predictions. When predicting the test data, it had equivalent type-1 and type-2 error rates. This balance is reflected in the f1-score of 81%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the complete statistical report on the final model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[528   4]\n",
      " [  4  17]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions_vc_soft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       532\n",
      "           1       0.81      0.81      0.81        21\n",
      "\n",
      "    accuracy                           0.99       553\n",
      "   macro avg       0.90      0.90      0.90       553\n",
      "weighted avg       0.99      0.99      0.99       553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions_vc_soft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9855334538878843\n",
      "F1-score: 0.8095238095238095\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:',scores_df[scores_df['Model']=='Soft Voting Classifier']['Accuracy'].iloc[0])\n",
    "print('F1-score:',scores_df[scores_df['Model']=='Soft Voting Classifier']['F1-Score'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6. Saving Test Data Frame with Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>G_sum</th>\n",
       "      <th>GS_sum</th>\n",
       "      <th>MP_sum</th>\n",
       "      <th>FG_sum</th>\n",
       "      <th>2P_sum</th>\n",
       "      <th>FT_sum</th>\n",
       "      <th>TRB_sum</th>\n",
       "      <th>AST_sum</th>\n",
       "      <th>PF_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>all_team_awards</th>\n",
       "      <th>league_awards</th>\n",
       "      <th>years_coaching</th>\n",
       "      <th>lottery</th>\n",
       "      <th>hof</th>\n",
       "      <th>all_star_count</th>\n",
       "      <th>championships</th>\n",
       "      <th>O</th>\n",
       "      <th>W</th>\n",
       "      <th>hof_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Norm Swanson</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frank Williams</td>\n",
       "      <td>86.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ray Scott</td>\n",
       "      <td>756.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23785.0</td>\n",
       "      <td>4364.0</td>\n",
       "      <td>4364.0</td>\n",
       "      <td>2628.0</td>\n",
       "      <td>7914.0</td>\n",
       "      <td>1778.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skip Harlicka</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Byron Irvin</td>\n",
       "      <td>87.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>Victor Alexander</td>\n",
       "      <td>286.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>5755.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Terry Davis</td>\n",
       "      <td>480.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>10369.0</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>2887.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>Quintin Dailey</td>\n",
       "      <td>528.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12170.0</td>\n",
       "      <td>2936.0</td>\n",
       "      <td>2915.0</td>\n",
       "      <td>1577.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>Sean Marks</td>\n",
       "      <td>230.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2275.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>John Rudometkin</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>553 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Player  G_sum  GS_sum   MP_sum  FG_sum  2P_sum  FT_sum  \\\n",
       "0        Norm Swanson   63.0     0.0    611.0    31.0    31.0    38.0   \n",
       "1      Frank Williams   86.0     3.0    952.0    92.0    68.0    45.0   \n",
       "2           Ray Scott  756.0     0.0  23785.0  4364.0  4364.0  2628.0   \n",
       "3       Skip Harlicka   26.0     0.0    218.0    41.0    41.0    24.0   \n",
       "4         Byron Irvin   87.0     8.0    849.0   165.0   158.0   114.0   \n",
       "..                ...    ...     ...      ...     ...     ...     ...   \n",
       "548  Victor Alexander  286.0   155.0   5755.0  1101.0  1083.0   322.0   \n",
       "549       Terry Davis  480.0   275.0  10369.0  1202.0  1199.0   654.0   \n",
       "550    Quintin Dailey  528.0   140.0  12170.0  2936.0  2915.0  1577.0   \n",
       "551        Sean Marks  230.0    11.0   2275.0   259.0   254.0   115.0   \n",
       "552   John Rudometkin  154.0     0.0   2020.0   366.0   366.0   228.0   \n",
       "\n",
       "     TRB_sum  AST_sum  PF_sum  ...  all_team_awards  league_awards  \\\n",
       "0      110.0     33.0    91.0  ...                0              0   \n",
       "1       77.0    166.0    87.0  ...                0              0   \n",
       "2     7914.0   1778.0  2250.0  ...                0              0   \n",
       "3       16.0     37.0    29.0  ...                0              0   \n",
       "4      123.0     73.0    77.0  ...                0              0   \n",
       "..       ...      ...     ...  ...              ...            ...   \n",
       "548   1384.0    257.0   713.0  ...                0              0   \n",
       "549   2887.0    273.0  1176.0  ...                0              0   \n",
       "550   1307.0   1188.0  1231.0  ...                0              0   \n",
       "551    501.0     50.0   342.0  ...                0              0   \n",
       "552    511.0     88.0   252.0  ...                0              0   \n",
       "\n",
       "     years_coaching  lottery  hof  all_star_count  championships  O  W  \\\n",
       "0                 0        0    0               0              0  0  1   \n",
       "1                 0        0    0               0              0  0  0   \n",
       "2                 4        1    0               0              0  0  0   \n",
       "3                 0        1    0               0              0  0  1   \n",
       "4                 0        0    0               0              0  0  0   \n",
       "..              ...      ...  ...             ...            ... .. ..   \n",
       "548               0        0    0               0              0  0  0   \n",
       "549               0        0    0               0              0  0  0   \n",
       "550               0        1    0               0              0  0  0   \n",
       "551               0        0    0               0              1  0  1   \n",
       "552               0        1    0               0              0  0  1   \n",
       "\n",
       "     hof_predicted  \n",
       "0                0  \n",
       "1                0  \n",
       "2                1  \n",
       "3                0  \n",
       "4                0  \n",
       "..             ...  \n",
       "548              0  \n",
       "549              0  \n",
       "550              0  \n",
       "551              0  \n",
       "552              0  \n",
       "\n",
       "[553 rows x 35 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_test.to_csv('./Data/final_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7. Comparisons and Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are actually very few other NBA hall-of-fame predictors. The most notable one was created by Basketball Reference, and it is commonly cited throughout sports media. From the information Basketball Reference provides, we can reasonably conclude that its model generates a recall score of around 75%. Our model did top this score with a recall score of 81% on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information on Basketball Reference's predictions and methodology can be found below:\n",
    "- Predictions: https://www.basketball-reference.com/leaders/hof_prob.html\n",
    "- Methodology: https://www.basketball-reference.com/about/hof_prob.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other applications of predictive modeling to the NBA. Teams are constantly looking to forecast player value, so these models do hold great importance. In the future, I would like to explore predicting if a player becomes an all-star during his career. The challenge to this project would be finding the sufficient amount of training data, but I believe much of the modeling methodology would be similar to that of this project. There is definitely a lot of freedom during data collection, data cleaning, and feature engineering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8. Future Improvements - Comprehensive List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the course of this project, I kept a running list of potential improvements that I would like to make in the future. Ultimately, I was unable to accomplish everything I wanted due to a lack of time or resources. With that being said, I am still quite happy with the results of this project, and I find it encouraging that there is plenty of room for improvement. \n",
    "\n",
    "Here is the breakdown of improvements by section:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Collection and Initial Cleaning\n",
    "- Find data with unique player IDs. We had to exclude many players because of issues with names during data merging. \n",
    "- Use a data source that is up to date. Since we used data from Kaggle, we had to exclude years after 2012. In the best case scenario, we should have been able to use data through 2017 because players can be inducted after three years of inactivity. \n",
    "- Verify correctness of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Feature Engineering and Data Merging\n",
    "- Focus less on coaching or remove players who have coaching experience. There is not a clear distinction in our data as to whether a player was inducted to the hall of fame for playing, coaching, or other contributions. We could eliminate confusion by taking out coaching entirely. \n",
    "- Include a position feature (e.g. point guard). \n",
    "- Use weighted average for aggregate statistics. Ideally, when we are finding mean statistics, we would like to avoid outlier seasons from skewing the mean. For example, seasons where a player played 20 games should not hold much weight. \n",
    "- Find ways to reduce null values from merging data. Fundamentally, we should focus on finding a better data source, but there probably are ways to make merging on name more successful. \n",
    "- Group the awards features in more meaningful ways. \n",
    "- Add a binary \"college or no college\" feature. \n",
    "- Determine how to combine statistics for players who changed names. Similarly, determine how to distinguish players who have repeated names. \n",
    "- Use natural language processing for features related to sentiment analysis. For example, popularity is certainly influential in a player's case for the hall of fame. On-court statistics cannot capture popularity very well. \n",
    "- Use per-possession statistics to account for changes in the NBA over time. Unmodified statistics tend to be either inflated or deflated depending on shot-clock rules, fouling tolerance, and other factors. Statistics that are based on each possession are more reflective of a player's abilities. \n",
    "- Add a feature that identifies the era in which a player played. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Exploratory Data Analysis and Preprocessing\n",
    "- Utilize sampling techniques to account for the imbalanced data. For example, we could have artifically generated more balanced data by performing synthetic minority oversampling technique (SMOTE). There are many other sampling possibilities. \n",
    "- Figure out how to impute modern statistics for pre-modern NBA players. It would be amazing to incorporate 3PT statistics and advanced statistics into the model. If imputation is unrealistic, perhaps we could make a successful model without removing null values. \n",
    "- Use VIF-score and other statistical metrics for feature selection. We decided to use PCA for feature selection, but it would be nice to gain a better understanding of which features matter the most in the model. \n",
    "- Select outliers in a more systematic way. Really, our basis was to investigate boxplots and use our best basketball judgement to filter out outliers. \n",
    "- See if one-hot encoding performs better than creating dummy variables. \n",
    "- Delay preprocessing until stratified k-fold cross-validation. \n",
    "- Select the proper number of principal components based on model performance. \n",
    "- Remove hall-of-fame outliers from the training data. One example is Fred Taylor, who happened to be an extremely successful NCAA coach. We had no way of knowing his coaching accolades, but he is clearly a statistical outlier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Modeling and Hyperparameter Tuning\n",
    "- Experiment to see if bootstrapping yields better performance than stratified k-fold cross-validation. It is widely known that bootstrapping can reduce variance despite an increase in bias. \n",
    "- Create dedicated functions/classes for modeling tasks. There is a lot of repetitive code during modeling and evaluation, and functions would help automate the process. \n",
    "- Tune the hyperparameters of the stacking classifier's final estimator. \n",
    "- Tune the neural-network hyperparametesr with GridSearchCV or manual cross-validation. We decided to tune hyperparameters based on a single training cycle, which can be highly variable. \n",
    "- Select the best models more rigorously. We should be looking at more than just the best f1-score on cross-validated, validation, and test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Testing Evaluation and Conclusions\n",
    "- Include the probabilities of classification for each player in the test data. That is, we should be able to see the confidence our final model had in classifying a player in a certain way. This information would allow us to directly compare our predictions with Basketball Reference's predictions.\n",
    "- Create running predictions for active players. These would be of interest to many NBA fans. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9. Last Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must note that there is always the possiblity of an inactive NBA player being inducted into the hall of fame. Therefore, it is critical that we continually update our data and model so that our predictions maintain accuracy. \n",
    "\n",
    "Additionally, we recognize that hall-of-fame criteria have likely changed over time. We can only expect our model to approximate a basis for the criteria. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
